{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport json\nimport nltk\nimport re\nimport csv\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"x_train= pd.read_csv('../input/radix-challenge/train.csv')\nx_test=pd.read_csv('../input/radix-challenge/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(pd.unique(x_train.genres))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DATA PREPARATION "},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for text cleaning \ndef clean_text(text):\n    # remove backslash-apostrophe \n    text = re.sub(\"\\'\", \"\", text) \n    # remove everything except alphabets \n    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n    # remove whitespaces \n    text = ' '.join(text.split()) \n    # convert text to lowercase \n    text = text.lower() \n    \n    return text\n\nx_train['clean_plot'] = x_train['synopsis'].apply(lambda x: clean_text(x))\nx_test['clean_plot'] = x_test['synopsis'].apply(lambda x: clean_text(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to remove all the stopwords that may affects the prestation of the model\nnltk.download('stopwords')\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\n\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)\n\nx_train['clean_plot'] = x_train['clean_plot'].apply(lambda x: remove_stopwords(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#estrapolate the genres vector from the train dataset\n\n\n#multilabel\ngen = [x.split(' ') for x in list (x_train['genres'])]    \n    #multiclass\n#gen1 = [[x] for x in list(x_train['genres'])]#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"set(x for l in gen for x in l)\n#there are in total 19 different categories","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## THE MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"#apply the onehot transformation for the genres vector\n\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nmultilabel_binarizer = MultiLabelBinarizer()\ny=multilabel_binarizer.fit_transform(gen)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape\n#this is perfect, cause it takes number of rows x number of different categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#using the 10k most frequent words in the synopsis through the Tf-idf features \n\ntfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# applying TF-IDF features to the synopsis\nxtrain_tfidf = tfidf_vectorizer.fit_transform(x_train['clean_plot'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\n# Binary Relevance\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Performance metric\nfrom sklearn.metrics import f1_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LogisticRegression()\nclf = OneVsRestClassifier(lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit model on train data\nclf.fit(xtrain_tfidf,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(tfidf_vectorizer.transform(x_test['clean_plot']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(multilabel_binarizer.inverse_transform(y_pred)))\npred_gen = multilabel_binarizer.inverse_transform(y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(data= {'movie_id':x_test.movie_id,'predicted_genres':pred_gen})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(submission.predicted_genres)):\n   submission.predicted_genres[i] =(','.join((submission.predicted_genres[i])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,len(submission.predicted_genres)):\n    submission.predicted_genres[i] = submission.predicted_genres[i].replace(\",\",\" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the model does not predict the genres for all the movies, maybe should be a good idea implement a multiclass model instead of multilabel, another option could be change the model, using something else instead of Onevstherest classifier."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}